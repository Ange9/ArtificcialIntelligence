{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A3: A\\*, IDS, and Effective Branching Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "2. [Overview](#overview)\n",
    "\n",
    "2. [A Search](#a*)\n",
    "\n",
    "2. [Iterative Deepening Search](#ids)\n",
    "\n",
    "4. [Effective Branching Factor](#ebf)\n",
    "\n",
    "5. [8-Puzzle](#8p)\n",
    "\n",
    " 5.1 [printPath_8p](#printPath_8p)\n",
    " \n",
    " 5.2 [findBlank_8p](#findBlank_8p)\n",
    " \n",
    " 5.3 [actionsF_8p](#actionsF_8p)\n",
    " \n",
    " 5.4 [takeActions_8p](#takeActionF_8p)\n",
    " \n",
    " 5.5 [goalTestF_8p](#goalTestF_8p)\n",
    " \n",
    "6. [Simple functions](#simple)\n",
    "\n",
    "7. [Heuristic functions](#heuristic)\n",
    "\n",
    "    7.1 [H1: Static value of zero](#h1_8p)\n",
    "    \n",
    "    7.2 [H2: Manhatthan distance](#h2_8p)\n",
    "    \n",
    "    7.3 [H3: Conflict lines](#h3_8p)\n",
    "    \n",
    "    7.4 [H4: Missplaced tiles](#h4_8p)\n",
    "8. [Run experiment](#runExp)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=overview></a>\n",
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, implement the Recursive Best-First Search\n",
    "implementation of the A\\* algorithm given in class.  Name this function `aStarSearch`.  Also in this notebook include your `iterativeDeepeningSearch` functions.  Define a new function named `ebf` that returns an estimate of the effective\n",
    "branching factor for a search algorithm applied to a search problem.\n",
    "\n",
    "So, the required functions are\n",
    "\n",
    "   - `aStarSearch(startState, actionsF, takeActionF, goalTestF, hF)`\n",
    "   - `iterativeDeepeningSearch(startState, goalState, actionsF, takeActionF, maxDepth)`\n",
    "   - `ebf(nNodes, depth)`, returns number of nodes expanded and depth reached during a search.\n",
    "\n",
    "Apply `iterativeDeepeningSearch` and `aStarSearch` to several eight-tile sliding puzzle\n",
    "problems. Compare their results by displayng\n",
    "solution path depth, number of nodes \n",
    "generated, and the effective branching factor, and discuss the results.  Do this by defining the following function that prints the table as shown in the example below.\n",
    "\n",
    "   - 'runExperiment(goalState1, goalState2, goalState3, [h1, h2, h3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic Functions\n",
    "\n",
    "For `aStarSearch` use the following two heuristic functions, plus one more of your own design, for a total of three heuristic functions.\n",
    "\n",
    "  * `h1(state, goal)`: $h(state, goal) = 0$, for all states $state$ and all goal states $goal$,\n",
    "  * `h2(state, goal)`: $h(state, goal) = m$, where $m$ is the Manhattan distance that the blank is from its goal position,\n",
    "  * `h3(state, goal)`: $h(state, goal) = ?$, that you define.  It must be admissible, and not constant for all states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply all four algorithms (`iterativeDeepeningSearch` plus `aStarSearch` with the three heuristic\n",
    "functions) to three eight-tile puzzle problems with start state\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "1 & 2 & 3\\\\\n",
    "4 & 0 & 5\\\\\n",
    "6 & 7 & 8\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "and these three goal states.\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccccccccccc}\n",
    "1 & 2 & 3  & ~~~~ & 1 & 2 & 3  &  ~~~~ & 1 & 0 &  3\\\\\n",
    "4 & 0 & 5  & & 4 & 5 & 8  & & 4 & 5 & 8\\\\\n",
    "6 & 7 & 8 &  & 6 & 0 & 7  & & 2 & 6 & 7\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a well-formatted table like the following.  Try to match this\n",
    "format. \n",
    "\n",
    "           [1, 2, 3, 4, 0, 5, 6, 7, 8]    [1, 2, 3, 4, 5, 8, 6, 0, 7]    [1, 0, 3, 4, 5, 8, 2, 6, 7] \n",
    "    Algorithm    Depth  Nodes  EBF              Depth  Nodes  EBF              Depth  Nodes  EBF          \n",
    "         IDS       0      0  0.000                3     43  3.086               11 225850  2.954         \n",
    "        A*h1       0      0  0.000                3    116  4.488               11 643246  3.263         \n",
    "        A*h2       0      0  0.000                3     51  3.297               11 100046  2.733         \n",
    "\n",
    "Of course you will have one more line for `h3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=a*></a>\n",
    "# A* Search\n",
    "The type of search that is done by this algorithm is an informed search as it chooses the next node to visit based on the domain knowledge given by the value of an function related to each step of the problem. \n",
    "\n",
    "The crucial component  in the A* search consist in the value of each state or node. This allows to reduce the time invested in reaching the goal state exponentially, given a certain start state. To compute the value for node \"state\", the following function is used:\n",
    "   <br>\n",
    "   <br> f(state) = g(state) + h(state)\n",
    "   \n",
    "   <br> having g as the cost to get to the goal state from the given start state, and h is the heuristic function, which will calculate the cost of all paths from the given state.\n",
    "   \n",
    "The  A* search function for this assigment was developed using the recursive implementation of the algorithm  provided by Dr. Chuck Anderson. The code was modified to count the number of nodes expanded in each search and the depth from the initial state to the goal state. Each state is represented as an instance of the class \"Node\" that contains the specific state and its f,g and h values.\n",
    "\n",
    "The heurisctic functions used to perform this type of search will be described later.\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, state,f=0, g=0 ,h=0):\n",
    "        self.state = state\n",
    "        self.f = f\n",
    "        self.g = g\n",
    "        self.h = h  \n",
    "        self.parent=Node\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Node(\" + repr(self.state) + \", f=\" + repr(self.f) + \\\n",
    "               \", g=\" + repr(self.g) + \", h=\" + repr(self.h) + \")\"\n",
    "\n",
    "def aStarSearch(startState, actionsF, takeActionF, goalTestF, hF):\n",
    "    global nNodes\n",
    "    global depth\n",
    "    nNodes=0\n",
    "    depth=0\n",
    "    h = hF(startState)\n",
    "    startNode = Node(state=startState, f=0+h, g=0, h=h)\n",
    "    a= aStarSearchHelper(startNode, actionsF, takeActionF, goalTestF, hF, float('inf'))\n",
    "    depth = len(a[0])-1\n",
    "    \n",
    "    return a\n",
    "\n",
    "def aStarSearchHelper(parentNode, actionsF, takeActionF, goalTestF, hF, fmax):\n",
    "    global nNodes\n",
    "    if goalTestF(parentNode.state):\n",
    "        return ([parentNode.state], parentNode.g)\n",
    "    ## Construct list of children nodes with f, g, and h values\n",
    "    actions = actionsF(parentNode.state)\n",
    "    if not actions:\n",
    "        return (\"failure\", float('inf'))\n",
    "    children = []\n",
    "    for action in actions:\n",
    "        (childState,stepCost) = takeActionF(parentNode.state, action)\n",
    "        h = hF(childState)\n",
    "        g = parentNode.g + stepCost\n",
    "        f = max(h+g, parentNode.f)\n",
    "        childNode = Node(state=childState, f=f, g=g, h=h)\n",
    "        children.append(childNode)\n",
    "        nNodes+=1\n",
    "\n",
    "    while True:\n",
    "        # find best child\n",
    "        children.sort(key = lambda n: n.f) # sort by f value\n",
    "        bestChild = children[0]\n",
    "        if bestChild.f > fmax:\n",
    "            return (\"failure\",bestChild.f)\n",
    "        # next lowest f value\n",
    "        alternativef = children[1].f if len(children) > 1 else float('inf')\n",
    "        # expand best child, reassign its f value to be returned value\n",
    "        result,bestChild.f = aStarSearchHelper(bestChild, actionsF, takeActionF, goalTestF,\n",
    "                                            hF, min(fmax,alternativef))\n",
    "        if result is not \"failure\":               \n",
    "            result.insert(0,parentNode.state)      \n",
    "            return (result, bestChild.f) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=ids></a>\n",
    "# Iterative Deepening Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *iterativeDeepeningSearch* algorithm will generate a path between a start and a goal state if it exists.\n",
    "This algorithm will call the *depthLimitedSearch* algorithm as many times as the value *maxDepth* shows, using a loop. If in one run within the loop a path is returned by the *depthLimitedSearch* algorithm, then the execution will not continue because it already found a solution. If in one of the call within the loop a  *cutoff* is returned, it means that with the given depth limit, the goal state was not found, so the loop will continue with a higher depth limit to try to reach the goal state. If the goal state is not in the graph, or it is not reachable from the given start state, then the algorithm will return  *failure*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterativeDeepeningSearch(startState, goalState, actionsF, takeActionF, maxDepth):\n",
    "    global nNodes\n",
    "    global depth\n",
    "    nodeCounter=0\n",
    "    nNodes=0\n",
    "    depth=0\n",
    "    path= 'cutoff'\n",
    "    p=[]\n",
    "    resultFound='false'\n",
    "    for x in range(maxDepth+1):\n",
    "        p= depthLimitedSearch(startState, goalState, actionsF, takeActionF, x)\n",
    "        nodeCounter+=nNodes\n",
    "        if p!='cutoff':\n",
    "            depth=0\n",
    "            if startState!=goalState:\n",
    "                depth=len(p)-1\n",
    "                nNodes=nodeCounter\n",
    "            return p\n",
    "        \n",
    "    if p=='cutoff':\n",
    "        return 'cutoff'\n",
    "    if p=='failure':\n",
    "        return 'failure'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *depthLimitedSearch* algorithm will receive a depth limit value that indicates how deep it should go in that run. To know how deeper is the node been consulted in that moment, it will check the *expanded* dictionary and will calculate how many steps are there from that node to the root. If it finds that the depth limit has been reached, it will not insert that node's children to the unexpanded list and will continue checking the neighbors.\n",
    "To generate the children for a certain node, the algorithm will use the functions *actionsF* and *takeActionF*.\n",
    "The purpose of the first function is to generate all possible actions that can be applied to a given state and the cost of that action. The second function will apply each of those actions to the state in order to generate all the children for that specific node.Every time a new state is generated from this actions, a global counter named *nNodes* will be incremented to keep track of how many nodes were expanded in a specific search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def depthLimitedSearch(startState , goalState, actionsF, takeActionF,depthLimit):\n",
    "    global nNodes\n",
    "    expanded={}\n",
    "    unexpanded= [(startState,\"None\")]\n",
    "    solutionPath=[]\n",
    "    existingChildren=[]\n",
    "    depth=0\n",
    "    needTuple='false'\n",
    "    end='true'\n",
    "    #If startState is the goalState, return the list containing just startState\n",
    "    if startState==goalState:\n",
    "        return startState\n",
    "    else:\n",
    "        while unexpanded:\n",
    "            #print unexpanded\n",
    "            #print expanded\n",
    "            \n",
    "            childrenAll=[]\n",
    "\n",
    "            #Pop from the end of unExpanded a (state, parent) pair.\n",
    "            (state,parent)= unexpanded.pop()\n",
    "            if(state not in existingChildren):\n",
    "                existingChildren.append(state);\n",
    "            if(parent not in existingChildren):\n",
    "                existingChildren.append(parent);\n",
    "\n",
    "            #Add the node to the expanded dictionary, indexed by its state.\n",
    "            if isinstance(state, list):\n",
    "                state= tuple(state)\n",
    "                needTuple= 'true'     \n",
    "                \n",
    "            expanded[state]=parent\n",
    "            \n",
    "            #check if depth limit has been reached\n",
    "            searchParent=parent\n",
    "            predecesor='true'\n",
    "            steps=0\n",
    "            while predecesor=='true':\n",
    "                if searchParent in expanded.keys():\n",
    "                    steps=steps+1\n",
    "                    searchParent=expanded[searchParent]              \n",
    "                else:\n",
    "                    predecesor='false'\n",
    "            children=[]\n",
    "            \n",
    "            \n",
    "            if steps < depthLimit:\n",
    "                #generates posible actions\n",
    "                listActions=actionsF(state)\n",
    "                #Generates successor depending on the posible moves  \n",
    "                for eachAction in listActions:\n",
    "                    c,cost=takeActionF(state, eachAction)\n",
    "                    nNodes+=1\n",
    "                    #c=takeActionF(state,eachAction)\n",
    "                    if c not in existingChildren:\n",
    "                        children.append(c)  \n",
    "                        \n",
    "                #reverse children list \n",
    "                children=list(reversed(children))\n",
    "                #insert children at the end of unexpanded list\n",
    "                for p in children:\n",
    "                    #state=list(state)\n",
    "                    unexpanded.append((p,state))\n",
    "            else:\n",
    "                 #generates posible actions\n",
    "                listActions=actionsF(state)\n",
    "                #Generates successor depending on the posible moves  \n",
    "                for eachAction in listActions:\n",
    "                    c,cost=takeActionF(state, eachAction)\n",
    "                    if c not in existingChildren:\n",
    "                        children.append(c) \n",
    "                if len(children) > 0:\n",
    "                    end='false'\n",
    "                children=[]     \n",
    "                \n",
    "        \n",
    "\n",
    "     \n",
    "            #If the goal has been found (in python, goalState is in children):\n",
    "            if goalState in children:  \n",
    "                solutionPath.append(goalState)\n",
    "                solutionPath.append(state)\n",
    "                while parent in expanded.values():\n",
    "                    if parent==\"None\":\n",
    "                        break\n",
    "                    solutionPath.append(parent)\n",
    "                    parent=expanded[parent]\n",
    "                if  needTuple=='true':\n",
    "                    newSolutionPath=[]\n",
    "                    for x in solutionPath:\n",
    "                        lst= list(x)\n",
    "                        newSolutionPath.append(lst)               \n",
    "                    solutionPath= newSolutionPath \n",
    "                return list(reversed(solutionPath))\n",
    "            \n",
    "         \n",
    "            \n",
    "        if  end=='true':\n",
    "            return \"failure\"\n",
    "        else:\n",
    "            return \"cutoff\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=ebf></a>\n",
    "# Effective Branching Factor\n",
    "\n",
    "The effective branching factor function  (ebf) is used to evaluate the effectiveness of a certain search using different goal states and heuristic functions in the case of A* search and different goal states and depth limits in the case of the iterative deepening search.\n",
    "\n",
    "After every execution of the search algorithm, a certain value has been assigned to the global variables *nNodes* and *depth*. The first value represents the total number of nodes processed during the search and the second  represents the depth in which the goal state was found.\n",
    "\n",
    "The purpose of this function is to evaluate how accurate is the heuristic function used to solve a A* search in relation to the real cost of going from the start state to the goal state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ebf(nodes, depth, precision=0.01):\n",
    "    result=0\n",
    "    d=depth\n",
    "    b=0\n",
    "    while (nodes-result) > precision:\n",
    "        result=(1-b**(d+1))/(1-b)\n",
    "        b+=precision\n",
    "        \n",
    "    return b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.320000000000001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebf(100, 12, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebf(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebf(1, 1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=8p></a>\n",
    "# 8-Puzzle\n",
    "The following are some of the functions used by the A* search algorithm and the iterative deepening search algorithm to solve the 8 puzzle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### printPath_8p\n",
    "<a id=printPath_8p></a>\n",
    "This function is used to print a certain state of the 8-puzzle or n-puzzle in a more readeble way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 3 \n",
      "4 2 5 \n",
      "6 7 8 \n"
     ]
    }
   ],
   "source": [
    "def printPath_8p(startState):\n",
    "    length= len(startState)\n",
    "    dim=0\n",
    "    for c in range(length):\n",
    "        counter=c**2\n",
    "        if counter==length: \n",
    "            dim=c              \n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "             print(startState[i*dim+j]), \n",
    "        print ('')\n",
    "\n",
    "startState=[1, 0, 3, 4, 2, 5, 6, 7, 8]\n",
    "printPath_8p(startState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=findBlank_8p></a>\n",
    "###     findBlank_8p\n",
    "This function will return the position (row and column) in which the blank tile is located.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def findBlank_8p(startState):\n",
    "    blankPosition=[]\n",
    "    length= len(startState)\n",
    "    dim= 0\n",
    "    for c in range(length):\n",
    "        counter=c**2\n",
    "        if counter==length: \n",
    "            dim=c \n",
    "    if 0 in startState:\n",
    "       \n",
    "        for row in range(dim):          \n",
    "             for column in range(dim): \n",
    "                    if startState[row*dim+column]==0:\n",
    "                        blankPosition.append(row)\n",
    "                        blankPosition.append(column)\n",
    "                        \n",
    "    return blankPosition\n",
    "\n",
    "findBlank_8p([1, 2, 3, 4, 0, 5, 6, 8, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=actionsF_8p></a>\n",
    "###      actionsF_8p\n",
    "\n",
    "The function *actionsF_8p* is used to generate all the possible directions where the zero can move in a certain state of the puzzle. The options will be returned in the the following order: left, right, up, down if all of them are valid moves.\n",
    "\n",
    "The way the algorithm works is: first assumes that all moves are valid, then it will check the borders and will remove any of the movements that is not valid for that state.\n",
    "\n",
    "For each valid action, the algorithm will return a pair containing the action an a number 1, indication that the cost to get from the given state to the child state using the corresponding action will be 1, or that the number of moves needed is 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('left', 1), ('right', 1), ('up', 1), ('down', 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def actionsF_8p(startState):\n",
    "   \n",
    "    action=[]\n",
    "    \n",
    "    #gets puzzle demension\n",
    "    dim=0\n",
    "    length= len(startState)\n",
    "    for c in range(length):\n",
    "        counter=c**2\n",
    "        if counter==length: \n",
    "            dim=c  \n",
    "    \n",
    "    blankPosition=findBlank_8p(startState)\n",
    "    row=blankPosition[0]\n",
    "    column=blankPosition[1]\n",
    "    blankPosition=row*dim+column\n",
    "   \n",
    "    #check if there is blank position\n",
    "    if blankPosition !=-1:\n",
    "        action=['left', 'right', 'up', 'down']\n",
    "      \n",
    "\n",
    "        #check left border\n",
    "        for row in range(dim):\n",
    "                if blankPosition in [row*dim]:\n",
    "                        action.remove('left')\n",
    "                        \n",
    "        #check right border\n",
    "        for row in range(dim):\n",
    "            if blankPosition in [(row*dim)+(dim-1)]:\n",
    "                     action.remove('right')\n",
    "        \n",
    "        #check top border\n",
    "        if blankPosition -dim <0:\n",
    "            action.remove('up')\n",
    "            \n",
    "        #check bottom border\n",
    "        if blankPosition +dim >=len(startState):\n",
    "            action.remove(\"down\")        \n",
    "    \n",
    "    actionCost=[]\n",
    "    for ac in action:\n",
    "        actionCost.append((ac,1))\n",
    "    return actionCost\n",
    "\n",
    "actionsF_8p([1, 2, 3, 4, 0, 5, 6, 8, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=takeActionF_8p></a>\n",
    "###     takeActionF_8p\n",
    "The *takeActionF_8p* function will receive a state and an action, consisting of a pair of the direction and the cost, and will generate a new state applying that action to the currect state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3, 0, 4, 5, 6, 8, 7], 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def takeActionF_8p(startState, act):\n",
    "\n",
    "    newState=[]\n",
    "    invalidLeft='false'\n",
    "    invalidRight='false'\n",
    "    invalidDown='false'\n",
    "    invalidUp='false'\n",
    "    #gets puzzle demension\n",
    "    dim=0\n",
    "    length= len(startState)\n",
    "    for c in range(length):\n",
    "        counter=c**2\n",
    "        if counter==length: \n",
    "            dim=c  \n",
    "    \n",
    "    blankPosition=findBlank_8p(startState)\n",
    "    row=blankPosition[0]\n",
    "    column=blankPosition[1]\n",
    "    blankPosition=row*dim+column\n",
    "    \n",
    "    \n",
    "    #check left border\n",
    "    for r in range(dim):\n",
    "        if blankPosition in [r*dim]:\n",
    "            invalidLeft='true'\n",
    "                   \n",
    "\n",
    "    #check right border\n",
    "    for row in range(dim):\n",
    "        if blankPosition in [(r*dim)+(dim-1)]:\n",
    "            invalidRight='true'\n",
    "\n",
    "    #check top border\n",
    "    if blankPosition -dim <0:\n",
    "         invalidUp='true'\n",
    "\n",
    "    #check bottom border\n",
    "    if blankPosition +dim >=len(startState):\n",
    "        invalidDown='true'  \n",
    "    \n",
    "    action=act[0]\n",
    "    pos=0\n",
    "    for x in startState:\n",
    "        newState.append(x)\n",
    "    if action=='left' and invalidLeft=='false':\n",
    "        pos=blankPosition\n",
    "        pos=pos-1\n",
    "        newState[blankPosition]=startState[pos]\n",
    "        newState[pos]=0\n",
    "    if action=='right'and invalidRight=='false':\n",
    "        pos=blankPosition\n",
    "        pos=pos+1\n",
    "        newState[blankPosition]=startState[pos]\n",
    "        newState[pos]=0\n",
    "    if action=='up' and invalidUp=='false':\n",
    "        pos=blankPosition\n",
    "        pos=pos-dim\n",
    "        newState[blankPosition]=startState[pos]\n",
    "        newState[pos]=0\n",
    "    if action=='down' and invalidDown=='false':\n",
    "        pos=blankPosition\n",
    "        pos=pos+dim      \n",
    "        newState[blankPosition]=startState[pos]\n",
    "        newState[pos]=0\n",
    "      \n",
    "    return (newState,act[1])\n",
    "takeActionF_8p([1, 2, 3, 4, 0, 5, 6, 8, 7],('left', 1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=goalTestF_8p></a>\n",
    "###      goalTestF_8p\n",
    "This function is used to evaluate if a certain state is the goal state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def goalTestF_8p(s,goal):\n",
    "    return s == goal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=simple></a>\n",
    "### Simple functions\n",
    "The following functions are used to solve  A* and IDS searches with values different than an 8-puzzle, for example graphs with characters or numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "succs= {'a': ['b', 'c'], \n",
    "              'b':['e', 'f', 'g'], \n",
    "              'b':['a'], \n",
    "              'c':['h'],\n",
    "              'h':['i'], \n",
    "              'i':['j', 'k', 'l'],\n",
    "              'k':['z']}\n",
    "                  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', 1), ('c', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def actionsF_simple(s):  \n",
    "    try:                                      \n",
    "        ## step cost of each action is 1\n",
    "        return [(succ,1) for succ in succs[s]]\n",
    "    except KeyError:\n",
    "        return []\n",
    "actionsF_simple('a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('left', 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def takeActionF_simple(state, action):\n",
    "    return action\n",
    "takeActionF_simple('a', ('left',1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def goalTestF(s):\n",
    "    return s == goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def h1(s):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def h_simple(s,g):\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def goalTestF_simple(s,goal):\n",
    "    return s == goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=heuristic></a>\n",
    "## Heuristic functions\n",
    "Heuristic functions are used in informed search problems. The objective of this functions is to guide the search to a certain path in which the cost to get to the goal state is the lesser possible for a certain state giving an estimate of the sum of the remaining step costs to a goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=h1_8p></a>\n",
    "### H1: Static value of zero\n",
    "This is a static heuristic function because it will always return a value of 0 no matter what the start and goal states are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def h1_8p(state, goal):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=h2_8p></a>\n",
    "\n",
    "### H2: Manhatthan distance\n",
    "\n",
    "A commun implementation of this algorithm describes that for a certain tile in a n-puzzle the Manhattan Distance will be the distance between its state and its position in the goal state.It means that, for a certain state the Manhattan distance will be the sum of the Manhattan distances of all the tiles without considering the blank tile.\n",
    "However, this implementation of the Manhattan distance heuristic function will consider only the number of spaces that the blank space is away from its goal state. Contrary to the first description, where every misplaces tile is considered to calculate the value returned by the heuristic function.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h2_8p(startState, goalState):\n",
    "    manhattanDistance=0\n",
    "    \n",
    "    statePosRow=0\n",
    "    statePosCol=0\n",
    "    goalPosRow=0\n",
    "    goalPosCol=0\n",
    "    \n",
    "    stateItem=0\n",
    "    goalItem=0\n",
    "    \n",
    "    length= len(startState)\n",
    "    dim= 0\n",
    "    for c in range(length):\n",
    "        counter=c**2\n",
    "        if counter==length: \n",
    "            dim=c \n",
    "    for row in range(dim):          \n",
    "        for column in range(dim):\n",
    "            stateItem=startState[row*dim+column]\n",
    "            goalItem=goalState[row*dim+column]\n",
    "            if stateItem!=goalItem and stateItem==0:\n",
    "                statePosRow=row\n",
    "                statePosCol=column\n",
    "                goalPosRow,goalPosCol=findPosition(goalState,stateItem)\n",
    "                x=abs(statePosRow-goalPosRow)+abs(statePosCol-goalPosCol)\n",
    "                manhattanDistance+=x\n",
    "            \n",
    "    return manhattanDistance\n",
    "\n",
    "#h2_8p([7,2,4,5,0,6,8,3,1], [0,1, 2, 3, 4, 5, 6, 7, 8] )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#given an item and  a state, returns the position of that item in the puzzle\n",
    "def findPosition(startState, item):\n",
    "    position=[]\n",
    "    length= len(startState)\n",
    "    dim= 0\n",
    "    for c in range(length):\n",
    "        counter=c**2\n",
    "        if counter==length: \n",
    "            dim=c \n",
    "    if item in startState:\n",
    "       \n",
    "        for row in range(dim):          \n",
    "             for column in range(dim): \n",
    "                    if startState[row*dim+column]==item:\n",
    "                        position.append(row)\n",
    "                        position.append(column)\n",
    "                        \n",
    "    return position\n",
    "\n",
    "#findPosition([1, 2, 4, 4, 5, 6, 7, 0, 8], 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=h3_8p></a>\n",
    "### H3: Linear conflict  \n",
    "This heuristic function is used as a complement of the Manhathan distance heuristic function.\n",
    "\n",
    "To determine if two tiles are having a linear conflict, the algorithm will check if both of them are in the same line, in this case, a line is represented by a row or column in the 8 puzzle. If both tiles are in the same line,  their goal states are also both in the same line and one of the tiles is blocked by the other tile, a linear conflict is present in that specific state of the puzzle.  \n",
    "\n",
    "The main approach of this function is that considers movements that are not counted by the Manhattan Distance heuristic function. If there are two tiles having a linear conflict, two movements are required to put both tiles in their goal position, moving one of them down and up again. This steps are not present in the result of a estimated remaining cost to the goal state using the simple Manhattan distance function.\n",
    "\n",
    "It is important to mention that the Manhattan distance function been used by the Linear conflict function, is the one that considers all the tiles that are not in place, excluding the blank tile. \n",
    "\n",
    "This algorithm does not add overestimation to the heuristic calculation of the remaining cost to get to the goal state, because it will not contemplate the same tile as part of more than one linear conflict, in this way the algorithm is just adding the two movements that the Manhattan distance dismisses for each misplaced tile, which retains the admissibility of the function.\n",
    "\n",
    "Even if the version of Manhattan distance considering all the tiles but the blank is used, it never overestimates the true cost to the solution, because it it considering every misplaced tile, and each of those tiles must be moved one or more positions to get to their goal state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def h3_8p(startState, goalState):\n",
    "    result=0\n",
    "    \n",
    "    length= len(startState)\n",
    "    dim= 0\n",
    "    for c in range(length):\n",
    "        counter=c**2\n",
    "        if counter==length: \n",
    "            dim=c \n",
    "    #Row Conflicts\n",
    "    for i in range(dim-1):\n",
    "        result += findConflicts(startState, i, 1,goalState);\n",
    "\n",
    "    #Column Conflicts\n",
    "    for i in range(dim-1):\n",
    "        result += findConflicts(startState, i, 0,goalState);\n",
    "\n",
    "    return h5_8p(startState,goalState)+2*result;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inConflict(index, a, b, indexA, indexB,  dimension,goalState):\n",
    "    indexGoalA = -1;\n",
    "    indexGoalB = -1;\n",
    "    r=0\n",
    "    \n",
    "    length= len(goalState)\n",
    "    dim= 0\n",
    "    for c in range(length):\n",
    "        counter=c**2\n",
    "        if counter==length: \n",
    "            dim=c \n",
    "    \n",
    "    for c in range(dim-1):\n",
    "        if dimension == 1 and goalState[index*dim+c]==a:\n",
    "            indexGoalA = c\n",
    "        elif dimension == 1 and goalState[index*dim+c]==b:\n",
    "            indexGoalB = c\n",
    "            \n",
    "        if dimension == 0 and goalState[c*dim+index]==a:\n",
    "            indexGoalA = c\n",
    "        elif dimension == 0 and goalState[c*dim+index]==b:\n",
    "            indexGoalB = c;\n",
    "                \n",
    "\n",
    "    if ((indexGoalA >= 0 and indexGoalB >= 0) and \n",
    "    ((indexA < indexB and indexGoalA > indexGoalB) or\n",
    "     (indexA > indexB and indexGoalA < indexGoalB))):\n",
    "        r=2\n",
    "    return r\n",
    "#InConflict(0, 2, 3, 0, 1,  1, [1, 2, 3, 4, 5, 6, 7, 8, 0])\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findConflicts(startState, i,  dimension,goalState):\n",
    "    result = 0;\n",
    "    tilesRelated = []\n",
    "    \n",
    "    length= len(startState)\n",
    "    dim= 0\n",
    "    for c in range(length):\n",
    "        counter=c**2\n",
    "        if counter==length: \n",
    "            dim=c \n",
    "    \n",
    "\n",
    "    #Loop foreach pair of elements in the row/column\n",
    "    h=0\n",
    "    while h< dim-1 and h not in tilesRelated:\n",
    "        k=h+1\n",
    "        while k < dim and h not in tilesRelated:\n",
    "            if dimension == 1 and startState[i*dim+h]==0:\n",
    "                k+=1\n",
    "                continue\n",
    "            if dimension == 0 and startState[h*dim+i]==0:\n",
    "                k+=1\n",
    "                continue\n",
    "            if dimension == 1 and startState[i*dim+k]==0:\n",
    "                k+=1\n",
    "                continue\n",
    "            if dimension == 0 and startState[k*dim+i]==0:\n",
    "                k+=1\n",
    "                continue\n",
    "                \n",
    "            if dimension ==1:\n",
    "                moves =inConflict(i, startState[i*dim+h], startState[i*dim+k], h, k, dimension, goalState)\n",
    "            else:\n",
    "                moves=inConflict(i, startState[h*dim+i], startState[k*dim+i], h, k, dimension,goalState)\n",
    "            \n",
    "            if (moves == 0):\n",
    "                k+=1\n",
    "                continue\n",
    "            result += 2;\n",
    "            tilesRelated.append(h)\n",
    "            tilesRelated.append(k)\n",
    "            k+=1   \n",
    "            break;\n",
    "        h+=1\n",
    "    return result\n",
    "    \n",
    "    \n",
    "#findConflicts([2,3,1,4,5,6,0,8,7], 2,  1, [1,2,3,4,5,6,7,8,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan Distance considering all the misplaced tiles\n",
    "This implementation of Manhattan Distance heuristic will consider all the misplaced tiles in relation with the goal state, but without considering the blank space.\n",
    "\n",
    "This is an admissible heuristic because even if it considers all the misplaced tiles, it will never overestimate the real cost because all the tiles must be moved at least one time form that specific state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def h5_8p(startState, goalState):\n",
    "    manhattanDistance=0\n",
    "    \n",
    "    statePosRow=0\n",
    "    statePosCol=0\n",
    "    goalPosRow=0\n",
    "    goalPosCol=0\n",
    "    \n",
    "    stateItem=0\n",
    "    goalItem=0\n",
    "    \n",
    "    length= len(startState)\n",
    "    dim= 0\n",
    "    for c in range(length):\n",
    "        counter=c**2\n",
    "        if counter==length: \n",
    "            dim=c \n",
    "    for row in range(dim):          \n",
    "        for column in range(dim):\n",
    "            stateItem=startState[row*dim+column]\n",
    "            goalItem=goalState[row*dim+column]\n",
    "            #consideres all the tiles but the blank \n",
    "            if stateItem!=goalItem and stateItem!=0:\n",
    "                statePosRow=row\n",
    "                statePosCol=column\n",
    "                goalPosRow,goalPosCol=findPosition(goalState,stateItem)\n",
    "                x=abs(statePosRow-goalPosRow)+abs(statePosCol-goalPosCol)\n",
    "                manhattanDistance+=x\n",
    "            \n",
    "    return manhattanDistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of a result executing the Manhattan Distance considering all the misplaced tiles: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5_8p([3, 2, 1, 4, 0, 5, 6, 7, 8],[1, 2, 3, 4, 0, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing this, the linear conflict function can be executed with the same start and goal states to show that 4 units were added to the result.  The result of linear conflict heuristic function will be:\n",
    "\n",
    "<br> Manhattan Distance considering all the misplaced tiles + 2 * linear conflicts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3_8p([3, 2, 1, 4, 0, 5, 6, 7, 8],[1, 2, 3, 4, 0, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=h4_8p></a>\n",
    "\n",
    "### H4: Misplaced tiles\n",
    "This heuristic function will return a value as a result of the sum of all the misplaced tiles that are found in a certain state of the puzzle.\n",
    "It is an admissible heuristic because for each of the misplaced tiles will add just 1 to the result, and the real cost to the goal state will include move each of those misplaced tiles at least one time, thus, it is not overstimating the real cost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def h4_8p(startState,goalState):\n",
    "    misplacedTiles=0\n",
    " \n",
    "    length= len(startState)\n",
    "    dim= 0\n",
    "    for c in range(length):\n",
    "        counter=c**2\n",
    "        if counter==length: \n",
    "            dim=c \n",
    "    for row in range(dim):          \n",
    "        for column in range(dim):\n",
    "            if startState[row*dim+column]!=goalState[row*dim+column]:\n",
    "                misplacedTiles+=1\n",
    "\n",
    "            \n",
    "    return misplacedTiles\n",
    "\n",
    "#h3([7,2,4,5,0,6,8,3,1], [3,2,4,5,6,0,8,7,1])'''\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=runExp></a>\n",
    "## Run Experiment\n",
    "In this section, some experiments are executed to compare the result of A* and IDS search algorithms with different goal states and different heuristic function. This will enable to possibility of compare the results to determine the performance of the heuristic functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runExperiment(goalState1, goalState2, goalState3, heuristicFunctions):\n",
    "    import pandas\n",
    "    import numpy as np\n",
    "    r=[]\n",
    "    #startState=[3, 5, 1, 4, 0, 2, 6, 7, 8]\n",
    "    startState=[1, 2, 3, 4, 0, 5, 6, 7, 8]\n",
    "    \n",
    "    \n",
    "    iterativeDeepeningSearch(startState, goalState1, actionsF_8p, takeActionF_8p, 20)\n",
    "    depth1=depth\n",
    "    nNodes1=nNodes\n",
    "    ebf1=ebf(nNodes1,depth1)\n",
    "\n",
    "    \n",
    "    iterativeDeepeningSearch(startState, goalState2, actionsF_8p, takeActionF_8p, 20)\n",
    "    depth2=depth\n",
    "    nNodes2=nNodes\n",
    "    ebf2=ebf(nNodes2,depth2)\n",
    "  \n",
    "\n",
    "    \n",
    "    iterativeDeepeningSearch(startState, goalState3, actionsF_8p, takeActionF_8p,20 )\n",
    "    depth3=depth\n",
    "    nNodes3=nNodes\n",
    "    ebf3=ebf(nNodes3,depth3)\n",
    " \n",
    "\n",
    "\n",
    "  \n",
    "    r.append(([depth1,nNodes1,ebf1],[depth2,nNodes2,ebf2],[depth3,nNodes3,ebf3]))     \n",
    "\n",
    "    for hF in heuristicFunctions:\n",
    "           \n",
    "            \n",
    "            depth0=0\n",
    "            nNodes0=0\n",
    "            ebf0=ebf(nNodes0,depth0)\n",
    "            aStarSearch(startState,actionsF_8p, takeActionF_8p,\n",
    "            lambda s: goalTestF_8p(s, goalState1),\n",
    "            lambda s: hF(s,goalState1))      \n",
    "            depth1=depth\n",
    "            nNodes1=nNodes\n",
    "            ebf1=ebf(nNodes1,depth1)\n",
    "            \n",
    "            \n",
    "            \n",
    "          \n",
    "            aStarSearch(startState,actionsF_8p, takeActionF_8p,\n",
    "            lambda s: goalTestF_8p(s, goalState2),\n",
    "            lambda s: hF(s,goalState2))   \n",
    "            depth2=depth\n",
    "            nNodes2=nNodes\n",
    "            ebf2=ebf(nNodes2,depth2)\n",
    "            \n",
    "            \n",
    "            aStarSearch(startState,actionsF_8p, takeActionF_8p,\n",
    "            lambda s: goalTestF_8p(s, goalState3),\n",
    "            lambda s: hF(s,goalState3))  \n",
    "            depth3=depth\n",
    "            nNodes3=nNodes\n",
    "            ebf3=ebf(nNodes3,depth3)\n",
    "            \n",
    "            \n",
    "            df=pandas\n",
    "            pd=pandas\n",
    "            \n",
    "            r.append(([depth1,nNodes1,ebf1],[depth2,nNodes2,ebf2],[depth3,nNodes3,ebf3]))\n",
    " \n",
    "    r0=r[0]\n",
    "    r1=r[1]\n",
    "    r2=r[2]\n",
    "    r3=r[3]\n",
    "    \n",
    "\n",
    "    return pd.DataFrame([( goalState1,'', '','',goalState2 ,'', '','',goalState3,  '', '',''),\n",
    "                        ( ' ','DEPTH', 'NODES','EBF','  ' ,'DEPTH', 'NODES','EBF',' ',  'DEPTH', 'NODES','EBF'),\n",
    "                         ( ' ',r0[0][0], r0[0][1],r0[0][2],' ' ,r0[1][0], r0[1][1],r0[1][2],' ',  r0[2][0], r0[2][1],r0[2][2]),\n",
    "                        ( ' ',r1[0][0], r1[0][1],r1[0][2],' ' ,r1[1][0], r1[1][1],r1[1][2],' ',  r1[2][0], r1[2][1],r1[2][2]),\n",
    "                        ( ' ',r2[0][0], r2[0][1],r2[0][2],' ' ,r2[1][0], r2[1][1],r2[1][2],' ',  r2[2][0], r2[2][1],r2[2][2]),\n",
    "                        ( ' ',r3[0][0], r3[0][1],r3[0][2],' ' ,r3[1][0], r3[1][1],r3[1][2],' ',  r3[2][0], r3[2][1],r3[2][2])], \n",
    "                       columns=['','','','','','','','','','','',''], index=['Goal State','Algorithms','IDS',heuristicFunctions[0].__name__,heuristicFunctions[1].__name__, heuristicFunctions[2].__name__])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing  Manhathan Distance with misplace tiles\n",
    "#### h2:manhattan distance considering only the blank tile\n",
    "#### h4:misplaced tiles\n",
    "#### startState=[1, 2, 3, 4, 0, 5, 6, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Goal State</th>\n",
       "      <td>[1, 2, 3, 4, 0, 5, 6, 7, 8]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[1, 2, 3, 4, 5, 8, 6, 0, 7]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[1, 0, 3, 4, 5, 8, 2, 6, 7]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms</th>\n",
       "      <td></td>\n",
       "      <td>DEPTH</td>\n",
       "      <td>NODES</td>\n",
       "      <td>EBF</td>\n",
       "      <td></td>\n",
       "      <td>DEPTH</td>\n",
       "      <td>NODES</td>\n",
       "      <td>EBF</td>\n",
       "      <td></td>\n",
       "      <td>DEPTH</td>\n",
       "      <td>NODES</td>\n",
       "      <td>EBF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDS</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>3.57</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>48288</td>\n",
       "      <td>2.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h1_8p</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>116</td>\n",
       "      <td>4.5</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>643246</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h2_8p</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>3.31</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>100046</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h4_8p</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.59</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>5232</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            \\\n",
       "Goal State  [1, 2, 3, 4, 0, 5, 6, 7, 8]                      \n",
       "Algorithms                               DEPTH  NODES  EBF   \n",
       "IDS                                          0      0    0   \n",
       "h1_8p                                        0      0    0   \n",
       "h2_8p                                        0      0    0   \n",
       "h4_8p                                        0      0    0   \n",
       "\n",
       "                                                             \\\n",
       "Goal State  [1, 2, 3, 4, 5, 8, 6, 0, 7]                       \n",
       "Algorithms                               DEPTH  NODES   EBF   \n",
       "IDS                                          3     62  3.57   \n",
       "h1_8p                                        3    116   4.5   \n",
       "h2_8p                                        3     51  3.31   \n",
       "h4_8p                                        3      9  1.59   \n",
       "\n",
       "                                                              \n",
       "Goal State  [1, 0, 3, 4, 5, 8, 2, 6, 7]                       \n",
       "Algorithms                               DEPTH   NODES   EBF  \n",
       "IDS                                         11   48288  2.56  \n",
       "h1_8p                                       11  643246  3.28  \n",
       "h2_8p                                       11  100046  2.75  \n",
       "h4_8p                                       11    5232  2.06  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runExperiment([1, 2, 3, 4, 0, 5, 6, 7, 8]   , [1, 2, 3, 4, 5, 8, 6, 0, 7]   , [1, 0, 3, 4, 5, 8, 2, 6, 7]  , [h1_8p, h2_8p, h4_8p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the most effective heuristic function is the h3 because for all the cases presents the lowest effective branching factor. This result is expected because the h2 function is using the Manhattan distance heuristic in a really optimistic way, considering only the blank tile, while the h3 function considers all the misplaced tiles but without overestimating the real cost.\n",
    "\n",
    "The h1 function will always have a greater EBF because it will no make any difference between the nodes to chose, since all of them in the same level will have the same *f* value, so the the search will choose the next node to visit randomly and not based on the posible lower cost to get to the goal state.\n",
    "\n",
    "The  EBF for the IDS is lower than the EBF using the manhattan distance considering only the blank tile, because this heuristic will generate more nodes than the other version of the manhattan distance that consideres all the  tiles. Compared to the misplace tiles heuristic function, is worst because will generate more innecesary nodes and this heuristic function avoids generating this unnecesary nodes estimating a higher cost to the goal state but never overestimating it. \n",
    "\n",
    "The IDS will be better than the h1 heuristic function since this heuristic will generate a huge amount of unnecesary nodes because it has no guide to determine the best path, while the IDS is limited by the depth limit used in each of the executions. The depth limit avoids generating extra nodes limiting the search instead of covering a hole branch of a certain node considering that the goal state might not be in the branch. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing both implementations of Manhattan Distance \n",
    "#### h2:manhattan distance considering only the blank tile\n",
    "#### h5:manhattan distance considering all the misplaced tiles\n",
    "#### startState=[1, 2, 3, 4, 0, 5, 6, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Goal State</th>\n",
       "      <td>[1, 2, 3, 4, 0, 5, 6, 7, 8]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[1, 2, 3, 4, 5, 8, 6, 0, 7]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[1, 0, 3, 4, 5, 8, 2, 6, 7]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms</th>\n",
       "      <td></td>\n",
       "      <td>DEPTH</td>\n",
       "      <td>NODES</td>\n",
       "      <td>EBF</td>\n",
       "      <td></td>\n",
       "      <td>DEPTH</td>\n",
       "      <td>NODES</td>\n",
       "      <td>EBF</td>\n",
       "      <td></td>\n",
       "      <td>DEPTH</td>\n",
       "      <td>NODES</td>\n",
       "      <td>EBF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDS</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>2.62</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>8419</td>\n",
       "      <td>2.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h1_8p</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>116</td>\n",
       "      <td>4.5</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>643246</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h2_8p</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>3.31</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>100046</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h5_8p</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.59</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>1172</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            \\\n",
       "Goal State  [1, 2, 3, 4, 0, 5, 6, 7, 8]                      \n",
       "Algorithms                               DEPTH  NODES  EBF   \n",
       "IDS                                          0      0    0   \n",
       "h1_8p                                        0      0    0   \n",
       "h2_8p                                        0      0    0   \n",
       "h5_8p                                        0      0    0   \n",
       "\n",
       "                                                             \\\n",
       "Goal State  [1, 2, 3, 4, 5, 8, 6, 0, 7]                       \n",
       "Algorithms                               DEPTH  NODES   EBF   \n",
       "IDS                                          3     28  2.62   \n",
       "h1_8p                                        3    116   4.5   \n",
       "h2_8p                                        3     51  3.31   \n",
       "h5_8p                                        3      9  1.59   \n",
       "\n",
       "                                                              \n",
       "Goal State  [1, 0, 3, 4, 5, 8, 2, 6, 7]                       \n",
       "Algorithms                               DEPTH   NODES   EBF  \n",
       "IDS                                         11    8419  2.16  \n",
       "h1_8p                                       11  643246  3.28  \n",
       "h2_8p                                       11  100046  2.75  \n",
       "h5_8p                                       11    1172  1.78  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runExperiment([1, 2, 3, 4, 0, 5, 6, 7, 8]   , [1, 2, 3, 4, 5, 8, 6, 0, 7]   , [1, 0, 3, 4, 5, 8, 2, 6, 7]  , [h1_8p, h2_8p, h5_8p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment the difference between h2 and h5 is considerable, because h2 is only considering the blank tile, while h5 is less optimistic and considers all the misplace tiles and remians addmissible. Both of them are admissible, so the h5 function in this case seems to be more effective.\n",
    "\n",
    "In this case as well, the IDS will be a bad option compared to the heuristic manhattan distance considering all the misplaced tiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manhattan Distance + Linear conflict \n",
    "#### h3:manhattan distance considering all the misplaced tiles+ linear conflict\n",
    "#### h5:manhattan distance considering all the misplaced tiles\n",
    "#### startState=1, 2, 3, 4, 0, 5, 6, 7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Goal State</th>\n",
       "      <td>[1, 2, 3, 4, 0, 5, 6, 7, 8]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[1, 2, 3, 4, 5, 8, 6, 0, 7]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[1, 0, 3, 4, 5, 8, 2, 6, 7]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithms</th>\n",
       "      <td></td>\n",
       "      <td>DEPTH</td>\n",
       "      <td>NODES</td>\n",
       "      <td>EBF</td>\n",
       "      <td></td>\n",
       "      <td>DEPTH</td>\n",
       "      <td>NODES</td>\n",
       "      <td>EBF</td>\n",
       "      <td></td>\n",
       "      <td>DEPTH</td>\n",
       "      <td>NODES</td>\n",
       "      <td>EBF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDS</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>2.62</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>8419</td>\n",
       "      <td>2.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h1_8p</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>116</td>\n",
       "      <td>4.5</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>643246</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h3_8p</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.59</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>1172</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h5_8p</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.59</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>1172</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            \\\n",
       "Goal State  [1, 2, 3, 4, 0, 5, 6, 7, 8]                      \n",
       "Algorithms                               DEPTH  NODES  EBF   \n",
       "IDS                                          0      0    0   \n",
       "h1_8p                                        0      0    0   \n",
       "h3_8p                                        0      0    0   \n",
       "h5_8p                                        0      0    0   \n",
       "\n",
       "                                                             \\\n",
       "Goal State  [1, 2, 3, 4, 5, 8, 6, 0, 7]                       \n",
       "Algorithms                               DEPTH  NODES   EBF   \n",
       "IDS                                          3     28  2.62   \n",
       "h1_8p                                        3    116   4.5   \n",
       "h3_8p                                        3      9  1.59   \n",
       "h5_8p                                        3      9  1.59   \n",
       "\n",
       "                                                              \n",
       "Goal State  [1, 0, 3, 4, 5, 8, 2, 6, 7]                       \n",
       "Algorithms                               DEPTH   NODES   EBF  \n",
       "IDS                                         11    8419  2.16  \n",
       "h1_8p                                       11  643246  3.28  \n",
       "h3_8p                                       11    1172  1.78  \n",
       "h5_8p                                       11    1172  1.78  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runExperiment([1, 2, 3, 4, 0, 5, 6, 7, 8]   , [1, 2, 3, 4, 5, 8, 6, 0, 7]   , [1, 0, 3, 4, 5, 8, 2, 6, 7]  , [h1_8p, h3_8p, h5_8p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately an example with a start state containing a linear conflict was not possible to execute because if a linear conflict is added on purpose to the start state, the algorithm will take more than 20 minutes to complete the search, and no solution was found to solve this issue. My initial guess is that simply with that given start state the algorithm will take to long to find the goal state.\n",
    "\n",
    "The result should be a ebf lower for the linear conflict heuristic because considering the 2 moves that the manhattan distances do not include, will make the function execute generating less unnecessary nodes but without overestimating the cost to find the goal state.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Other examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'c', 'h', 'i', 'k', 'z']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterativeDeepeningSearch('a', 'z', actionsF_simple, takeActionF_simple, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['a', 'c', 'h', 'i', 'k', 'z'], 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aStarSearch('a',actionsF_simple, takeActionF_simple,\n",
    "            lambda s: goalTestF_simple(s, 'z'),\n",
    "            lambda s: h_simple(s, 'z'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 2, 3, 4, 5, 6, 7, 0, 8],\n",
       "  [1, 2, 3, 4, 0, 6, 7, 5, 8],\n",
       "  [1, 2, 3, 0, 4, 6, 7, 5, 8],\n",
       "  [0, 2, 3, 1, 4, 6, 7, 5, 8]],\n",
       " 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aStarSearch([1, 2, 3, 4, 5, 6, 7, 0, 8],\n",
    "                     actionsF_8p, takeActionF_8p,\n",
    "                     lambda s: goalTestF_8p(s, [0, 2, 3, 1, 4,  6, 7, 5, 8]),\n",
    "                     lambda s: h1_8p(s, [0, 2, 3, 1, 4,  6, 7, 5, 8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cutoff'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterativeDeepeningSearch([5, 2, 8, 0, 1, 4, 3, 7, 6], \n",
    "                                 [0, 2, 3, 1, 4,  6, 7, 5, 8],\n",
    "                                 actionsF_8p, takeActionF_8p, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing actionsF_8p([1, 2, 3, 4, 5, 6, 7, 0, 8])\n",
      "('\\n--- 5/5 points. Your actionsF_8p correctly returned', [('left', 1), ('right', 1), ('up', 1)])\n",
      "\n",
      "Testing takeActionF_8p([1, 2, 3, 4, 5, 6, 7, 0, 8], (up, 1))\n",
      "('\\n--- 5/5 points. Your takeActionsF_8p correctly returned', ([1, 2, 3, 4, 0, 6, 7, 5, 8], 1))\n",
      "\n",
      "Testing goalTestF_8p([1, 2, 3, 4, 5, 6, 7, 0, 8], [1, 2, 3, 4, 5, 6, 7, 0, 8])\n",
      "\n",
      "--- 5/5 points. Your goalTestF_8p correctly True\n",
      "\n",
      "Testing aStarSearch([1, 2, 3, 4, 5, 6, 7, 0, 8],\n",
      "                     actionsF_8p, takeActionF_8p,\n",
      "                     lambda s: goalTestF_8p(s, [0, 2, 3, 1, 4,  6, 7, 5, 8]),\n",
      "                     lambda s: h1_8p(s, [0, 2, 3, 1, 4,  6, 7, 5, 8]))\n",
      "('\\n--- 20/20 points. Your search correctly returned', ([[1, 2, 3, 4, 5, 6, 7, 0, 8], [1, 2, 3, 4, 0, 6, 7, 5, 8], [1, 2, 3, 0, 4, 6, 7, 5, 8], [0, 2, 3, 1, 4, 6, 7, 5, 8]], 3))\n",
      "\n",
      "Testing iterativeDeepeningSearch([5, 2, 8, 0, 1, 4, 3, 7, 6], \n",
      "                                 [0, 2, 3, 1, 4,  6, 7, 5, 8],\n",
      "                                 actionsF_8p, takeActionF_8p, 10)\n",
      "('\\n--- 15/15 points. Your search correctly returned', 'cutoff')\n",
      "\n",
      "AI Grade is 50/50\n"
     ]
    }
   ],
   "source": [
    "%run -i A3grader.py"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
